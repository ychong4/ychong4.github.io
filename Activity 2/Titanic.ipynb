{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9080cd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86db1905",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrain = pd.read_csv(\"train.csv\")\n",
    "dfTest = pd.read_csv(\"test.csv\")\n",
    "dfGender = pd.read_csv(\"gender_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3aa7f6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([dfTrain, dfTest], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0b61bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1       0.0       3   \n",
       "1            2       1.0       1   \n",
       "2            3       1.0       3   \n",
       "3            4       1.0       1   \n",
       "4            5       0.0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01d4632e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1309 entries, 0 to 417\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  1309 non-null   int64  \n",
      " 1   Survived     891 non-null    float64\n",
      " 2   Pclass       1309 non-null   int64  \n",
      " 3   Name         1309 non-null   object \n",
      " 4   Sex          1309 non-null   object \n",
      " 5   Age          1046 non-null   float64\n",
      " 6   SibSp        1309 non-null   int64  \n",
      " 7   Parch        1309 non-null   int64  \n",
      " 8   Ticket       1309 non-null   object \n",
      " 9   Fare         1308 non-null   float64\n",
      " 10  Cabin        295 non-null    object \n",
      " 11  Embarked     1307 non-null   object \n",
      "dtypes: float64(3), int64(4), object(5)\n",
      "memory usage: 132.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e0ca315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1046.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1308.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>655.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.294882</td>\n",
       "      <td>29.881138</td>\n",
       "      <td>0.498854</td>\n",
       "      <td>0.385027</td>\n",
       "      <td>33.295479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>378.020061</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.837836</td>\n",
       "      <td>14.413493</td>\n",
       "      <td>1.041658</td>\n",
       "      <td>0.865560</td>\n",
       "      <td>51.758668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>328.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>655.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>982.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived       Pclass          Age        SibSp  \\\n",
       "count  1309.000000  891.000000  1309.000000  1046.000000  1309.000000   \n",
       "mean    655.000000    0.383838     2.294882    29.881138     0.498854   \n",
       "std     378.020061    0.486592     0.837836    14.413493     1.041658   \n",
       "min       1.000000    0.000000     1.000000     0.170000     0.000000   \n",
       "25%     328.000000    0.000000     2.000000    21.000000     0.000000   \n",
       "50%     655.000000    0.000000     3.000000    28.000000     0.000000   \n",
       "75%     982.000000    1.000000     3.000000    39.000000     1.000000   \n",
       "max    1309.000000    1.000000     3.000000    80.000000     8.000000   \n",
       "\n",
       "             Parch         Fare  \n",
       "count  1309.000000  1308.000000  \n",
       "mean      0.385027    33.295479  \n",
       "std       0.865560    51.758668  \n",
       "min       0.000000     0.000000  \n",
       "25%       0.000000     7.895800  \n",
       "50%       0.000000    14.454200  \n",
       "75%       0.000000    31.275000  \n",
       "max       9.000000   512.329200  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "719c63c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId       0\n",
       "Survived        418\n",
       "Pclass            0\n",
       "Name              0\n",
       "Sex               0\n",
       "Age             263\n",
       "SibSp             0\n",
       "Parch             0\n",
       "Ticket            0\n",
       "Fare              1\n",
       "Cabin          1014\n",
       "Embarked          2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cf03cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column name:  PassengerId  --- Unique value counts:  1309\n",
      "Column name:  Survived  --- Unique value counts:  2\n",
      "Column name:  Pclass  --- Unique value counts:  3\n",
      "Column name:  Name  --- Unique value counts:  1307\n",
      "Column name:  Sex  --- Unique value counts:  2\n",
      "Column name:  Age  --- Unique value counts:  98\n",
      "Column name:  SibSp  --- Unique value counts:  7\n",
      "Column name:  Parch  --- Unique value counts:  8\n",
      "Column name:  Ticket  --- Unique value counts:  929\n",
      "Column name:  Fare  --- Unique value counts:  281\n",
      "Column name:  Cabin  --- Unique value counts:  186\n",
      "Column name:  Embarked  --- Unique value counts:  3\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(\"Column name: \", col, \" --- Unique value counts: \", df[col].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c98ce88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index using passenger IDs\n",
    "df = df.set_index(\"PassengerId\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a98ef36",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb3bdb5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist(bins=30, figsize=(12, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa239e26",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "288ceb74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId\n",
       "1       Braund\n",
       "2      Cumings\n",
       "3    Heikkinen\n",
       "4     Futrelle\n",
       "5        Allen\n",
       "Name: LastName, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create column LastName\n",
    "df['LastName'] = df['Name'].str.split(', ').str[0]\n",
    "\n",
    "df['LastName'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdff1f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr              757\n",
       "Miss            260\n",
       "Mrs             197\n",
       "Master           61\n",
       "Rev               8\n",
       "Dr                8\n",
       "Col               4\n",
       "Mlle              2\n",
       "Ms                2\n",
       "Major             2\n",
       "Lady              1\n",
       "Mme               1\n",
       "Jonkheer          1\n",
       "Sir               1\n",
       "Dona              1\n",
       "Don               1\n",
       "Capt              1\n",
       "the Countess      1\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cretae column Title\n",
    "nameSplit = df['Name'].str.split(', ').str[1]\n",
    "df['Title'] = nameSplit.str.split('.').str[0]\n",
    "\n",
    "df['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b18f9ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr       759\n",
       "Miss     265\n",
       "Mrs      200\n",
       "Noble     85\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regroup some titles\n",
    "mrs = ['Lady', 'Mlle']\n",
    "miss = ['Dona', 'the Countess', 'Mme', 'Ms']\n",
    "mr = ['Jonkheer', 'Don']\n",
    "noble = ['Dr', 'Col', 'Major', 'Capt', 'Sir', 'Rev', 'Master']\n",
    "df.loc[df.Title.isin(mrs), 'Title'] = 'Mrs'\n",
    "df.loc[df.Title.isin(miss), 'Title'] = 'Miss'\n",
    "df.loc[df.Title.isin(mr), 'Title'] = 'Mr'\n",
    "df.loc[df.Title.isin(noble), 'Title'] = 'Noble'\n",
    "\n",
    "df['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b63289b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill Age missing values\n",
    "mean_age = df['Age'].mean()\n",
    "\n",
    "df['Age'] = df['Age'].fillna(value = mean_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a37c262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    1014\n",
       "C      94\n",
       "B      65\n",
       "D      46\n",
       "E      41\n",
       "A      22\n",
       "F      21\n",
       "G       5\n",
       "T       1\n",
       "Name: CabinGroup, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create column CabinGroup using first letter of Cabin\n",
    "df['CabinGroup'] = df['Cabin'].astype('str').str[0]\n",
    "df['CabinGroup'] = df['CabinGroup'].str.upper()\n",
    "\n",
    "df['CabinGroup'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d619071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CabinGroup\n",
       "A    0.466667\n",
       "B    0.744681\n",
       "C    0.593220\n",
       "D    0.757576\n",
       "E    0.750000\n",
       "F    0.615385\n",
       "G    0.500000\n",
       "N    0.299854\n",
       "T    0.000000\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the survival rate of Cabin Groups\n",
    "df.groupby('CabinGroup')['Survived'].aggregate('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11926e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Fare 0 and replace with NaN\n",
    "df.loc[df.Fare.eq(0), 'Fare'] = np.nan\n",
    "\n",
    "# Split ticket by series and number\n",
    "df['TicketSeries'] = [i[0] if len(i) > 1 else 0 for i in df.Ticket.str.split()]\n",
    "df['TicketNumber'] = [i[-1] for i in df.Ticket.str.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ecb51f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column price = ticket number / number of passenger with same number\n",
    "ticketDict = df.groupby('TicketNumber')['LastName'].count().to_dict()\n",
    "\n",
    "df['Price'] = df.Fare / df['TicketNumber'].map(ticketDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3530e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Price'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96c06bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <th>CabinGroup</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">1</th>\n",
       "      <th>A</th>\n",
       "      <td>21.0</td>\n",
       "      <td>32.818748</td>\n",
       "      <td>7.058487</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>27.720800</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>50.495800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>62.0</td>\n",
       "      <td>41.543635</td>\n",
       "      <td>24.062267</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>28.989600</td>\n",
       "      <td>36.491071</td>\n",
       "      <td>44.779700</td>\n",
       "      <td>128.082300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>94.0</td>\n",
       "      <td>35.949407</td>\n",
       "      <td>9.950084</td>\n",
       "      <td>25.258333</td>\n",
       "      <td>27.720825</td>\n",
       "      <td>33.604163</td>\n",
       "      <td>43.450000</td>\n",
       "      <td>68.389600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>40.0</td>\n",
       "      <td>30.022813</td>\n",
       "      <td>5.741721</td>\n",
       "      <td>19.700000</td>\n",
       "      <td>25.986100</td>\n",
       "      <td>26.550000</td>\n",
       "      <td>37.625000</td>\n",
       "      <td>39.133350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>34.0</td>\n",
       "      <td>26.544241</td>\n",
       "      <td>4.570400</td>\n",
       "      <td>8.795833</td>\n",
       "      <td>26.550000</td>\n",
       "      <td>26.900000</td>\n",
       "      <td>27.719433</td>\n",
       "      <td>38.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>64.0</td>\n",
       "      <td>32.922205</td>\n",
       "      <td>15.776900</td>\n",
       "      <td>13.275000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>27.720800</td>\n",
       "      <td>38.011607</td>\n",
       "      <td>128.082300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>1.0</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>35.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2</th>\n",
       "      <th>D</th>\n",
       "      <td>6.0</td>\n",
       "      <td>13.595833</td>\n",
       "      <td>0.829640</td>\n",
       "      <td>12.875000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.395850</td>\n",
       "      <td>13.844800</td>\n",
       "      <td>15.045800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>4.0</td>\n",
       "      <td>10.275000</td>\n",
       "      <td>3.513427</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>9.187500</td>\n",
       "      <td>11.425000</td>\n",
       "      <td>12.512500</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>13.0</td>\n",
       "      <td>10.423077</td>\n",
       "      <td>1.607441</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>9.750000</td>\n",
       "      <td>9.750000</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>248.0</td>\n",
       "      <td>11.661995</td>\n",
       "      <td>2.083982</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>12.806250</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">3</th>\n",
       "      <th>E</th>\n",
       "      <td>3.0</td>\n",
       "      <td>6.841667</td>\n",
       "      <td>1.046447</td>\n",
       "      <td>6.237500</td>\n",
       "      <td>6.237500</td>\n",
       "      <td>6.237500</td>\n",
       "      <td>7.143750</td>\n",
       "      <td>8.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>8.0</td>\n",
       "      <td>7.532646</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>7.229200</td>\n",
       "      <td>7.396875</td>\n",
       "      <td>7.650000</td>\n",
       "      <td>7.650000</td>\n",
       "      <td>7.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.432500</td>\n",
       "      <td>0.183715</td>\n",
       "      <td>5.231250</td>\n",
       "      <td>5.231250</td>\n",
       "      <td>5.566667</td>\n",
       "      <td>5.566667</td>\n",
       "      <td>5.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>688.0</td>\n",
       "      <td>7.359087</td>\n",
       "      <td>1.408806</td>\n",
       "      <td>1.807300</td>\n",
       "      <td>7.061975</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>7.925000</td>\n",
       "      <td>19.966700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count       mean        std        min        25%  \\\n",
       "Pclass CabinGroup                                                      \n",
       "1      A            21.0  32.818748   7.058487  26.000000  27.720800   \n",
       "       B            62.0  41.543635  24.062267   5.000000  28.989600   \n",
       "       C            94.0  35.949407   9.950084  25.258333  27.720825   \n",
       "       D            40.0  30.022813   5.741721  19.700000  25.986100   \n",
       "       E            34.0  26.544241   4.570400   8.795833  26.550000   \n",
       "       N            64.0  32.922205  15.776900  13.275000  26.000000   \n",
       "       T             1.0  35.500000        NaN  35.500000  35.500000   \n",
       "2      D             6.0  13.595833   0.829640  12.875000  13.000000   \n",
       "       E             4.0  10.275000   3.513427   5.250000   9.187500   \n",
       "       F            13.0  10.423077   1.607441   8.666667   9.750000   \n",
       "       N           248.0  11.661995   2.083982   5.250000  10.500000   \n",
       "3      E             3.0   6.841667   1.046447   6.237500   6.237500   \n",
       "       F             8.0   7.532646   0.204545   7.229200   7.396875   \n",
       "       G             5.0   5.432500   0.183715   5.231250   5.231250   \n",
       "       N           688.0   7.359087   1.408806   1.807300   7.061975   \n",
       "\n",
       "                         50%        75%         max  \n",
       "Pclass CabinGroup                                    \n",
       "1      A           30.500000  35.500000   50.495800  \n",
       "       B           36.491071  44.779700  128.082300  \n",
       "       C           33.604163  43.450000   68.389600  \n",
       "       D           26.550000  37.625000   39.133350  \n",
       "       E           26.900000  27.719433   38.500000  \n",
       "       N           27.720800  38.011607  128.082300  \n",
       "       T           35.500000  35.500000   35.500000  \n",
       "2      D           13.395850  13.844800   15.045800  \n",
       "       E           11.425000  12.512500   13.000000  \n",
       "       F            9.750000  10.500000   13.000000  \n",
       "       N           12.806250  13.000000   16.000000  \n",
       "3      E            6.237500   7.143750    8.050000  \n",
       "       F            7.650000   7.650000    7.750000  \n",
       "       G            5.566667   5.566667    5.566667  \n",
       "       N            7.750000   7.925000   19.966700  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['Pclass', 'CabinGroup'])['Price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1641c0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>TicketNumber</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LINE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>1</td>\n",
       "      <td>B94</td>\n",
       "      <td>112059</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LINE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>239853</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LINE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>239853</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>239853</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>239854</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LINE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112052</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>239856</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>239855</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>1</td>\n",
       "      <td>A36</td>\n",
       "      <td>112050</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>1</td>\n",
       "      <td>B102</td>\n",
       "      <td>112058</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19972</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3701</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112051</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>1</td>\n",
       "      <td>B52 B54 B56</td>\n",
       "      <td>112058</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass        Cabin TicketNumber  Price\n",
       "PassengerId                                         \n",
       "180               3          NaN         LINE    NaN\n",
       "264               1          B94       112059    NaN\n",
       "272               3          NaN         LINE    NaN\n",
       "278               2          NaN       239853    NaN\n",
       "303               3          NaN         LINE    NaN\n",
       "414               2          NaN       239853    NaN\n",
       "467               2          NaN       239853    NaN\n",
       "482               2          NaN       239854    NaN\n",
       "598               3          NaN         LINE    NaN\n",
       "634               1          NaN       112052    NaN\n",
       "675               2          NaN       239856    NaN\n",
       "733               2          NaN       239855    NaN\n",
       "807               1          A36       112050    NaN\n",
       "816               1         B102       112058    NaN\n",
       "823               1          NaN        19972    NaN\n",
       "1044              3          NaN         3701    NaN\n",
       "1158              1          NaN       112051    NaN\n",
       "1264              1  B52 B54 B56       112058    NaN"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Price missing value\n",
    "ticket = df[df.Price.isna()]\n",
    "\n",
    "ticket[['Pclass', 'Cabin', 'TicketNumber', 'Price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "634473f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>LastName</th>\n",
       "      <th>Title</th>\n",
       "      <th>CabinGroup</th>\n",
       "      <th>TicketSeries</th>\n",
       "      <th>TicketNumber</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ward, Miss. Anna</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17755</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>Ward</td>\n",
       "      <td>Miss</td>\n",
       "      <td>N</td>\n",
       "      <td>PC</td>\n",
       "      <td>17755</td>\n",
       "      <td>128.0823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cardeza, Mr. Thomas Drake Martinez</td>\n",
       "      <td>male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PC 17755</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>B51 B53 B55</td>\n",
       "      <td>C</td>\n",
       "      <td>Cardeza</td>\n",
       "      <td>Mr</td>\n",
       "      <td>B</td>\n",
       "      <td>PC</td>\n",
       "      <td>17755</td>\n",
       "      <td>128.0823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Lesurer, Mr. Gustave J</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17755</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>B101</td>\n",
       "      <td>C</td>\n",
       "      <td>Lesurer</td>\n",
       "      <td>Mr</td>\n",
       "      <td>B</td>\n",
       "      <td>PC</td>\n",
       "      <td>17755</td>\n",
       "      <td>128.0823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Cardeza, Mrs. James Warburton Martinez (Charlo...</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PC 17755</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>B51 B53 B55</td>\n",
       "      <td>C</td>\n",
       "      <td>Cardeza</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>B</td>\n",
       "      <td>PC</td>\n",
       "      <td>17755</td>\n",
       "      <td>128.0823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "259               1.0       1   \n",
       "680               1.0       1   \n",
       "738               1.0       1   \n",
       "1235              NaN       1   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "259                                           Ward, Miss. Anna  female  35.0   \n",
       "680                         Cardeza, Mr. Thomas Drake Martinez    male  36.0   \n",
       "738                                     Lesurer, Mr. Gustave J    male  35.0   \n",
       "1235         Cardeza, Mrs. James Warburton Martinez (Charlo...  female  58.0   \n",
       "\n",
       "             SibSp  Parch    Ticket      Fare        Cabin Embarked LastName  \\\n",
       "PassengerId                                                                    \n",
       "259              0      0  PC 17755  512.3292          NaN        C     Ward   \n",
       "680              0      1  PC 17755  512.3292  B51 B53 B55        C  Cardeza   \n",
       "738              0      0  PC 17755  512.3292         B101        C  Lesurer   \n",
       "1235             0      1  PC 17755  512.3292  B51 B53 B55        C  Cardeza   \n",
       "\n",
       "            Title CabinGroup TicketSeries TicketNumber     Price  \n",
       "PassengerId                                                       \n",
       "259          Miss          N           PC        17755  128.0823  \n",
       "680            Mr          B           PC        17755  128.0823  \n",
       "738            Mr          B           PC        17755  128.0823  \n",
       "1235          Mrs          B           PC        17755  128.0823  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Price outliers\n",
    "df.loc[df.Price > 100,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9cb582ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>CabinGroup</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>32.818748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>41.543635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>35.949407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>30.022813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>26.544241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>32.922205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>T</td>\n",
       "      <td>35.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>D</td>\n",
       "      <td>13.595833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>E</td>\n",
       "      <td>10.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>10.423077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>11.661995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>E</td>\n",
       "      <td>6.841667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>7.532646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>G</td>\n",
       "      <td>5.432500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>7.359087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Pclass CabinGroup      Price\n",
       "0        1          A  32.818748\n",
       "1        1          B  41.543635\n",
       "2        1          C  35.949407\n",
       "3        1          D  30.022813\n",
       "4        1          E  26.544241\n",
       "5        1          N  32.922205\n",
       "6        1          T  35.500000\n",
       "7        2          D  13.595833\n",
       "8        2          E  10.275000\n",
       "9        2          F  10.423077\n",
       "10       2          N  11.661995\n",
       "11       3          E   6.841667\n",
       "12       3          F   7.532646\n",
       "13       3          G   5.432500\n",
       "14       3          N   7.359087"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priceDf = df.groupby(['Pclass', 'CabinGroup'])['Price'].mean().reset_index()\n",
    "priceDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "905dfa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace outliers with mean price\n",
    "mean_1b = priceDf\n",
    "\n",
    "df.loc[df.TicketNumber.eq('17755'), 'Price'] = mean_1b\n",
    "\n",
    "# Impute missing prices\n",
    "for index, row in df.loc[df.Price.isna(), ['Pclass', 'CabinGroup']].iterrows():\n",
    "    new_price = priceDf.loc[priceDf.Pclass.eq(row.Pclass) & priceDf.CabinGroup.eq(row.CabinGroup)].Price.mean()\n",
    "    df.loc[[index], 'Price'] = new_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74e25219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill Embark missing values\n",
    "mode_embarked = df['Embarked'].mode()\n",
    "df['Embarked'] = df['Embarked'].fillna(value = mode_embarked[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba92a28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column FamilyOnBoard\n",
    "\n",
    "df['FamilyOnBoard'] = df['SibSp'] + df['Parch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e71a855b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1309 entries, 1 to 1309\n",
      "Data columns (total 18 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Survived       891 non-null    float64\n",
      " 1   Pclass         1309 non-null   int64  \n",
      " 2   Name           1309 non-null   object \n",
      " 3   Sex            1309 non-null   object \n",
      " 4   Age            1309 non-null   float64\n",
      " 5   SibSp          1309 non-null   int64  \n",
      " 6   Parch          1309 non-null   int64  \n",
      " 7   Ticket         1309 non-null   object \n",
      " 8   Fare           1291 non-null   float64\n",
      " 9   Cabin          295 non-null    object \n",
      " 10  Embarked       1309 non-null   object \n",
      " 11  LastName       1309 non-null   object \n",
      " 12  Title          1309 non-null   object \n",
      " 13  CabinGroup     1309 non-null   object \n",
      " 14  TicketSeries   1309 non-null   object \n",
      " 15  TicketNumber   1309 non-null   object \n",
      " 16  Price          1309 non-null   float64\n",
      " 17  FamilyOnBoard  1309 non-null   int64  \n",
      "dtypes: float64(4), int64(4), object(10)\n",
      "memory usage: 226.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55e9b01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived         1.000000\n",
       "Price            0.269999\n",
       "Fare             0.252453\n",
       "Parch            0.081629\n",
       "FamilyOnBoard    0.016639\n",
       "SibSp           -0.035322\n",
       "Age             -0.070323\n",
       "Pclass          -0.338481\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correlation to Survived\n",
    "df.corr()['Survived'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8cbc18b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Survived status vs Age\n",
    "survived = df[df['Survived'].eq(1)]\n",
    "survivedNot = df[df['Survived'].eq(0)]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "survived['Age'].plot(kind='kde', label='Survived')\n",
    "survivedNot['Age'].plot(kind='kde', label='Not survived')\n",
    "plt.xlim(0,100)\n",
    "plt.xticks(np.arange(0, 101, 5))\n",
    "plt.legend()\n",
    "plt.xlabel('Age')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8bc1b2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    872\n",
       "2    322\n",
       "0    115\n",
       "Name: AgeGroup, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create column Age Group\n",
    "# 0-15 : Group 0\n",
    "# 15-35 : Group 1\n",
    "# 35+ : Group 2\n",
    "\n",
    "df['AgeGroup'] = pd.cut(x = df.Age, labels = [0,1,2], bins=[-1, 15, 35, df.Age.max()])\n",
    "\n",
    "df.AgeGroup.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "565dc473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Survived status vs Price\n",
    "survived = df[df['Survived'].eq(1)]\n",
    "survivedNot = df[df['Survived'].eq(0)]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "survived['Price'].plot(kind='kde', label='Survived')\n",
    "survivedNot['Price'].plot(kind='kde', label='Not survived')\n",
    "plt.xlim(0,df.Price.max())\n",
    "plt.xticks(np.arange(0, df.Price.max()+1, 5))\n",
    "plt.legend()\n",
    "plt.xlabel('Price')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "517470e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    955\n",
       "1    347\n",
       "2      7\n",
       "Name: PriceGroup, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Price Group\n",
    "# 0-13 : Group 0\n",
    "# 13-58 : Group 1\n",
    "# 58+: Group 2\n",
    "\n",
    "df['PriceGroup'] = pd.cut(x = df.Price, labels = [0,1,2], bins=[-1, 13, 58, df.Price.max()])\n",
    "\n",
    "df.PriceGroup.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16f8f082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Survived status vs FamilyOnBoard\n",
    "survived = df[df['Survived'].eq(1)]\n",
    "survivedNot = df[df['Survived'].eq(0)]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "survived['FamilyOnBoard'].plot(kind='kde', label='Survived')\n",
    "survivedNot['FamilyOnBoard'].plot(kind='kde', label='Not survived')\n",
    "plt.xlim(0,df.FamilyOnBoard.max())\n",
    "plt.legend()\n",
    "plt.xlabel('Family Numbers')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55f64416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1025\n",
       "1     224\n",
       "2      60\n",
       "Name: FamilySizeGroup, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create FamilySizeGroup\n",
    "# 0-1: Group 0\n",
    "# 1-4: Group 1\n",
    "# 4+: Group 2\n",
    "\n",
    "df['FamilySizeGroup'] = pd.cut(x = df.FamilyOnBoard, labels = [0,1,2], bins=[-1, 1, 4, df.FamilyOnBoard.max()])\n",
    "\n",
    "df.FamilySizeGroup.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3538181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply np.log to normalize the skewed right Price\n",
    "df.Price = df.Price.apply(np.log1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b84aeb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1309 entries, 1 to 1309\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype   \n",
      "---  ------           --------------  -----   \n",
      " 0   Survived         891 non-null    float64 \n",
      " 1   Pclass           1309 non-null   int64   \n",
      " 2   Sex              1309 non-null   object  \n",
      " 3   Age              1309 non-null   float64 \n",
      " 4   SibSp            1309 non-null   int64   \n",
      " 5   Parch            1309 non-null   int64   \n",
      " 6   Embarked         1309 non-null   object  \n",
      " 7   Title            1309 non-null   object  \n",
      " 8   CabinGroup       1309 non-null   object  \n",
      " 9   Price            1309 non-null   float64 \n",
      " 10  FamilyOnBoard    1309 non-null   int64   \n",
      " 11  AgeGroup         1309 non-null   category\n",
      " 12  PriceGroup       1309 non-null   category\n",
      " 13  FamilySizeGroup  1309 non-null   category\n",
      "dtypes: category(3), float64(3), int64(4), object(4)\n",
      "memory usage: 159.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Drop unused columns\n",
    "\n",
    "df = df.drop(columns=['Name', 'LastName', 'Ticket', 'Cabin', 'TicketSeries', 'TicketNumber', 'Fare'])\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1144945b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numerical and cateforical columns\n",
    "num_col = ['Age', 'SibSp', 'Parch', 'Price', 'FamilyOnBoard']\n",
    "cat_col = ['Pclass', 'Sex', 'CabinGroup', 'Embarked', 'AgeGroup', 'PriceGroup', 'FamilySizeGroup', 'Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7224a6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One Hot Encoding for categorical columns\n",
    "le = OneHotEncoder()\n",
    "le.fit(df[cat_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f5f504ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=cat_col)\n",
    "\n",
    "dfTrain = df[0:891]\n",
    "dfTest = df[891:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "77bf9c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Price</th>\n",
       "      <th>FamilyOnBoard</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>...</th>\n",
       "      <th>PriceGroup_0</th>\n",
       "      <th>PriceGroup_1</th>\n",
       "      <th>PriceGroup_2</th>\n",
       "      <th>FamilySizeGroup_0</th>\n",
       "      <th>FamilySizeGroup_1</th>\n",
       "      <th>FamilySizeGroup_2</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Noble</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.110213</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.601186</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.188856</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.316003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.202765</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0.0</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0.0</td>\n",
       "      <td>29.881138</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.926072</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1.0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.433987</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0.0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.169054</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows  36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived        Age  SibSp  Parch     Price  FamilyOnBoard  \\\n",
       "PassengerId                                                               \n",
       "1                 0.0  22.000000      1      0  2.110213              1   \n",
       "2                 1.0  38.000000      1      0  3.601186              1   \n",
       "3                 1.0  26.000000      0      0  2.188856              0   \n",
       "4                 1.0  35.000000      1      0  3.316003              1   \n",
       "5                 0.0  35.000000      0      0  2.202765              0   \n",
       "...               ...        ...    ...    ...       ...            ...   \n",
       "887               0.0  27.000000      0      0  2.639057              0   \n",
       "888               1.0  19.000000      0      0  3.433987              0   \n",
       "889               0.0  29.881138      1      2  1.926072              3   \n",
       "890               1.0  26.000000      0      0  3.433987              0   \n",
       "891               0.0  32.000000      0      0  2.169054              0   \n",
       "\n",
       "             Pclass_1  Pclass_2  Pclass_3  Sex_female  ...  PriceGroup_0  \\\n",
       "PassengerId                                            ...                 \n",
       "1                   0         0         1           0  ...             1   \n",
       "2                   1         0         0           1  ...             0   \n",
       "3                   0         0         1           1  ...             1   \n",
       "4                   1         0         0           1  ...             0   \n",
       "5                   0         0         1           0  ...             1   \n",
       "...               ...       ...       ...         ...  ...           ...   \n",
       "887                 0         1         0           0  ...             1   \n",
       "888                 1         0         0           1  ...             0   \n",
       "889                 0         0         1           1  ...             1   \n",
       "890                 1         0         0           0  ...             0   \n",
       "891                 0         0         1           0  ...             1   \n",
       "\n",
       "             PriceGroup_1  PriceGroup_2  FamilySizeGroup_0  FamilySizeGroup_1  \\\n",
       "PassengerId                                                                     \n",
       "1                       0             0                  1                  0   \n",
       "2                       1             0                  1                  0   \n",
       "3                       0             0                  1                  0   \n",
       "4                       1             0                  1                  0   \n",
       "5                       0             0                  1                  0   \n",
       "...                   ...           ...                ...                ...   \n",
       "887                     0             0                  1                  0   \n",
       "888                     1             0                  1                  0   \n",
       "889                     0             0                  0                  1   \n",
       "890                     1             0                  1                  0   \n",
       "891                     0             0                  1                  0   \n",
       "\n",
       "             FamilySizeGroup_2  Title_Miss  Title_Mr  Title_Mrs  Title_Noble  \n",
       "PassengerId                                                                   \n",
       "1                            0           0         1          0            0  \n",
       "2                            0           0         0          1            0  \n",
       "3                            0           1         0          0            0  \n",
       "4                            0           0         0          1            0  \n",
       "5                            0           0         1          0            0  \n",
       "...                        ...         ...       ...        ...          ...  \n",
       "887                          0           0         0          0            1  \n",
       "888                          0           1         0          0            0  \n",
       "889                          0           1         0          0            0  \n",
       "890                          0           0         1          0            0  \n",
       "891                          0           0         1          0            0  \n",
       "\n",
       "[891 rows x 36 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8bd20442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Price</th>\n",
       "      <th>FamilyOnBoard</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>...</th>\n",
       "      <th>PriceGroup_0</th>\n",
       "      <th>PriceGroup_1</th>\n",
       "      <th>PriceGroup_2</th>\n",
       "      <th>FamilySizeGroup_0</th>\n",
       "      <th>FamilySizeGroup_1</th>\n",
       "      <th>FamilySizeGroup_2</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Noble</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>34.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.178064</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.369075</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.268252</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.966238</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>29.881138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.202765</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.618993</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>38.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.110213</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>29.881138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.202765</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>29.881138</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.134494</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows  35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Age  SibSp  Parch     Price  FamilyOnBoard  Pclass_1  \\\n",
       "PassengerId                                                               \n",
       "892          34.500000      0      0  2.178064              0         0   \n",
       "893          47.000000      1      0  2.079442              1         0   \n",
       "894          62.000000      0      0  2.369075              0         0   \n",
       "895          27.000000      0      0  2.268252              0         0   \n",
       "896          22.000000      1      1  1.966238              2         0   \n",
       "...                ...    ...    ...       ...            ...       ...   \n",
       "1305         29.881138      0      0  2.202765              0         0   \n",
       "1306         39.000000      0      0  3.618993              0         1   \n",
       "1307         38.500000      0      0  2.110213              0         0   \n",
       "1308         29.881138      0      0  2.202765              0         0   \n",
       "1309         29.881138      1      1  2.134494              2         0   \n",
       "\n",
       "             Pclass_2  Pclass_3  Sex_female  Sex_male  ...  PriceGroup_0  \\\n",
       "PassengerId                                            ...                 \n",
       "892                 0         1           0         1  ...             1   \n",
       "893                 0         1           1         0  ...             1   \n",
       "894                 1         0           0         1  ...             1   \n",
       "895                 0         1           0         1  ...             1   \n",
       "896                 0         1           1         0  ...             1   \n",
       "...               ...       ...         ...       ...  ...           ...   \n",
       "1305                0         1           0         1  ...             1   \n",
       "1306                0         0           1         0  ...             0   \n",
       "1307                0         1           0         1  ...             1   \n",
       "1308                0         1           0         1  ...             1   \n",
       "1309                0         1           0         1  ...             1   \n",
       "\n",
       "             PriceGroup_1  PriceGroup_2  FamilySizeGroup_0  FamilySizeGroup_1  \\\n",
       "PassengerId                                                                     \n",
       "892                     0             0                  1                  0   \n",
       "893                     0             0                  1                  0   \n",
       "894                     0             0                  1                  0   \n",
       "895                     0             0                  1                  0   \n",
       "896                     0             0                  0                  1   \n",
       "...                   ...           ...                ...                ...   \n",
       "1305                    0             0                  1                  0   \n",
       "1306                    1             0                  1                  0   \n",
       "1307                    0             0                  1                  0   \n",
       "1308                    0             0                  1                  0   \n",
       "1309                    0             0                  0                  1   \n",
       "\n",
       "             FamilySizeGroup_2  Title_Miss  Title_Mr  Title_Mrs  Title_Noble  \n",
       "PassengerId                                                                   \n",
       "892                          0           0         1          0            0  \n",
       "893                          0           0         0          1            0  \n",
       "894                          0           0         1          0            0  \n",
       "895                          0           0         1          0            0  \n",
       "896                          0           0         0          1            0  \n",
       "...                        ...         ...       ...        ...          ...  \n",
       "1305                         0           0         1          0            0  \n",
       "1306                         0           1         0          0            0  \n",
       "1307                         0           0         1          0            0  \n",
       "1308                         0           0         1          0            0  \n",
       "1309                         0           0         0          0            1  \n",
       "\n",
       "[418 rows x 35 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTest = dfTest.drop(columns=['Survived'])\n",
    "\n",
    "dfTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce82daba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-42-1d37379bbc87>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfTrain[num_col] = sc.fit_transform(dfTrain[num_col])\n",
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    }
   ],
   "source": [
    "# Normalization for numeric columns\n",
    "sc = StandardScaler()\n",
    "\n",
    "dfTrain[num_col] = sc.fit_transform(dfTrain[num_col])\n",
    "dfTest[num_col] = sc.fit_transform(dfTest[num_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2ea990b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfTrain.drop(columns=['Survived'])\n",
    "Y = dfTrain['Survived']\n",
    "X_test = dfTest\n",
    "\n",
    "X_train, X_dev, Y_train, Y_dev = train_test_split(X, Y, test_size = 0.2, random_state = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4621177",
   "metadata": {},
   "source": [
    "# Model 1: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "590f3bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=3, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=3, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=3, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=3, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=3, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=3, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=3, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=3, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=3, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=3, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=3, n_estimators=5000; total time=   4.5s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=3, n_estimators=5000; total time=   4.5s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=3, n_estimators=5000; total time=   4.5s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=3, n_estimators=5000; total time=   4.5s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=3, n_estimators=5000; total time=   4.5s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, n_estimators=1000; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, n_estimators=5000; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, n_estimators=5000; total time=   4.5s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, n_estimators=5000; total time=   4.5s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, n_estimators=5000; total time=   4.5s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=5, n_estimators=5000; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=8, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=8, n_estimators=1000; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=8, n_estimators=1000; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=8, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=8, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=8, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=8, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=8, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=8, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=8, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=8, n_estimators=5000; total time=   4.5s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=8, n_estimators=5000; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=8, n_estimators=5000; total time=   4.5s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=8, n_estimators=5000; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=8, n_estimators=5000; total time=   4.5s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=1000; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=2000; total time=   2.0s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=5000; total time=   4.7s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=5000; total time=   4.7s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=5000; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=5000; total time=   4.7s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=3, n_estimators=5000; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=1000; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=5000; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=5000; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=5000; total time=   4.7s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=5000; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=5, n_estimators=5000; total time=   4.7s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=8, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=8, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=8, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=8, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=8, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=8, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=8, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=8, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=8, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=8, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=8, n_estimators=5000; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=8, n_estimators=5000; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=8, n_estimators=5000; total time=   4.5s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=8, n_estimators=5000; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=8, min_samples_leaf=8, n_estimators=5000; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=1000; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=1000; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=1000; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=5000; total time=   4.7s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=5000; total time=   4.7s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=5000; total time=   4.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=5000; total time=   4.7s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=3, n_estimators=5000; total time=   4.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, n_estimators=5000; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, n_estimators=5000; total time=   4.7s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, n_estimators=5000; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, n_estimators=5000; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=5, n_estimators=5000; total time=   4.7s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=8, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=8, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=8, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=8, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=8, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=8, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=8, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=8, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=8, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=8, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=8, n_estimators=5000; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=8, n_estimators=5000; total time=   4.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=8, n_estimators=5000; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=8, n_estimators=5000; total time=   4.6s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=8, n_estimators=5000; total time=   4.5s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=3, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=3, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=3, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=3, n_estimators=1000; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=3, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=3, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=3, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=3, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=3, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=3, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=3, n_estimators=5000; total time=   4.6s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=3, n_estimators=5000; total time=   4.7s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=3, n_estimators=5000; total time=   4.6s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=3, n_estimators=5000; total time=   4.5s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=3, n_estimators=5000; total time=   4.6s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, n_estimators=5000; total time=   4.5s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, n_estimators=5000; total time=   4.6s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, n_estimators=5000; total time=   4.5s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, n_estimators=5000; total time=   4.6s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=5, n_estimators=5000; total time=   4.6s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=8, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=8, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=8, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=8, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=8, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=8, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=8, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=8, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=8, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=8, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=8, n_estimators=5000; total time=   4.6s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=8, n_estimators=5000; total time=   4.5s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=8, n_estimators=5000; total time=   4.5s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=8, n_estimators=5000; total time=   4.7s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=8, n_estimators=5000; total time=   4.6s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=1000; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=1000; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=2000; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=5000; total time=   4.7s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=5000; total time=   4.7s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=5000; total time=   4.8s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=5000; total time=   4.8s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=3, n_estimators=5000; total time=   4.8s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=1000; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=5000; total time=   4.7s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=5000; total time=   4.8s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=5000; total time=   4.7s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=5000; total time=   4.7s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=5, n_estimators=5000; total time=   4.7s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=8, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=8, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=8, n_estimators=1000; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=8, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=8, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=8, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=8, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=8, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=8, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=8, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=8, n_estimators=5000; total time=   4.7s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=8, n_estimators=5000; total time=   4.6s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=8, n_estimators=5000; total time=   4.7s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=8, n_estimators=5000; total time=   4.6s\n",
      "[CV] END criterion=entropy, max_depth=8, min_samples_leaf=8, n_estimators=5000; total time=   4.8s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=1000; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=1000; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=1000; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=1000; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=1000; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=2000; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=2000; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=2000; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=5000; total time=   4.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=5000; total time=   4.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=5000; total time=   4.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=5000; total time=   4.8s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=3, n_estimators=5000; total time=   4.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, n_estimators=1000; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, n_estimators=1000; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, n_estimators=1000; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, n_estimators=2000; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, n_estimators=5000; total time=   4.8s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, n_estimators=5000; total time=   4.8s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, n_estimators=5000; total time=   4.8s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, n_estimators=5000; total time=   4.8s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=5, n_estimators=5000; total time=   4.7s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=8, n_estimators=1000; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=8, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=8, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=8, n_estimators=1000; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=8, n_estimators=1000; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=8, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=8, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=8, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=8, n_estimators=2000; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=8, n_estimators=2000; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=8, n_estimators=5000; total time=   4.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=8, n_estimators=5000; total time=   4.7s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=8, n_estimators=5000; total time=   4.7s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=8, n_estimators=5000; total time=   4.7s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=8, n_estimators=5000; total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=3, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=3, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=3, n_estimators=1000; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=3, n_estimators=1000; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=3, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=3, n_estimators=2000; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=3, n_estimators=2000; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=3, n_estimators=2000; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=3, n_estimators=2000; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=3, n_estimators=2000; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=3, n_estimators=5000; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=3, n_estimators=5000; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=3, n_estimators=5000; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=3, n_estimators=5000; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=3, n_estimators=5000; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=5, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=5, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=5, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=5, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=5, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=5, n_estimators=2000; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=5, n_estimators=2000; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=5, n_estimators=2000; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=5, n_estimators=2000; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=5, n_estimators=2000; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=5, n_estimators=5000; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=5, n_estimators=5000; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=5, n_estimators=5000; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=5, n_estimators=5000; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=5, n_estimators=5000; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=8, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=8, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=8, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=8, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=8, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=8, n_estimators=2000; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=8, n_estimators=2000; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=8, n_estimators=2000; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=8, n_estimators=2000; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=8, n_estimators=2000; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=8, n_estimators=5000; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=8, n_estimators=5000; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=8, n_estimators=5000; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=8, n_estimators=5000; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=5, min_samples_leaf=8, n_estimators=5000; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=3, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=3, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=3, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=3, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=3, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=3, n_estimators=2000; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=3, n_estimators=2000; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=3, n_estimators=2000; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=3, n_estimators=2000; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=3, n_estimators=2000; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=3, n_estimators=5000; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=3, n_estimators=5000; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=3, n_estimators=5000; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=3, n_estimators=5000; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=3, n_estimators=5000; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=5, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=5, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=5, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=5, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=5, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=5, n_estimators=2000; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=5, n_estimators=2000; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=5, n_estimators=2000; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=5, n_estimators=2000; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=5, n_estimators=2000; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=5, n_estimators=5000; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=5, n_estimators=5000; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=5, n_estimators=5000; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=5, n_estimators=5000; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=5, n_estimators=5000; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=8, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=8, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=8, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=8, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=8, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=8, n_estimators=2000; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=8, n_estimators=2000; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=8, n_estimators=2000; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=8, n_estimators=2000; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=8, n_estimators=2000; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=8, n_estimators=5000; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=8, n_estimators=5000; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=8, n_estimators=5000; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=8, n_estimators=5000; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=8, min_samples_leaf=8, n_estimators=5000; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=3, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=3, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=3, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=3, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=3, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=3, n_estimators=2000; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=3, n_estimators=2000; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=3, n_estimators=2000; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=3, n_estimators=2000; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=3, n_estimators=2000; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=3, n_estimators=5000; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=3, n_estimators=5000; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=3, n_estimators=5000; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=3, n_estimators=5000; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=3, n_estimators=5000; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=5, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=5, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=5, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=5, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=5, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=5, n_estimators=2000; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=5, n_estimators=2000; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=5, n_estimators=2000; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=5, n_estimators=2000; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=5, n_estimators=2000; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=5, n_estimators=5000; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=5, n_estimators=5000; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=5, n_estimators=5000; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=5, n_estimators=5000; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=5, n_estimators=5000; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=8, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=8, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=8, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=8, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=8, n_estimators=1000; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=8, n_estimators=2000; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=8, n_estimators=2000; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=8, n_estimators=2000; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=8, n_estimators=2000; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=8, n_estimators=2000; total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=8, n_estimators=5000; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=8, n_estimators=5000; total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=8, n_estimators=5000; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=8, n_estimators=5000; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/yaowhuichong/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.82299813 0.82439673 0.82579533 0.82019108 0.82159953 0.82159953\n",
      " 0.81177977 0.81317837 0.81317837 0.82860238 0.82579533 0.82719393\n",
      " 0.82298828 0.81877278 0.82157983 0.81878263 0.81457697 0.81315867\n",
      " 0.82578548 0.82579533 0.82438688 0.82017138 0.82438688 0.82018123\n",
      " 0.81175022 0.81315867 0.81176007 0.82439673 0.82439673 0.82439673\n",
      " 0.82159953 0.82159953 0.82159953 0.81317837 0.81457697 0.81457697\n",
      " 0.82720378 0.82438688 0.82578548 0.82579533 0.82438688 0.82438688\n",
      " 0.82017138 0.81176007 0.81458682 0.82860238 0.82719393 0.82439673\n",
      " 0.82298828 0.82578548 0.82156998 0.81878263 0.81597557 0.81597557\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, max_depth=10, min_samples_leaf=8, n_estimators=5000; total time=   1.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
       "                         'max_depth': [5, 8, 10], 'min_samples_leaf': [3, 5, 8],\n",
       "                         'n_estimators': [1000, 2000, 5000]},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier()\n",
    "\n",
    "param = {'n_estimators': [1000, 2000, 5000],\n",
    "        'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "        'max_depth': [5, 8, 10],\n",
    "        'min_samples_leaf': [3, 5, 8]\n",
    "        }\n",
    "\n",
    "rf_clf_cv = GridSearchCV(rf_clf, param_grid = param, scoring = 'accuracy', cv=5, verbose=2)\n",
    "rf_clf_cv.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e4d416dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(**rf_clf_cv.best_params_)\n",
    "\n",
    "rf_clf.fit(X_train, Y_train)\n",
    "Y_pred_rf_train = rf_clf.predict(X_train)\n",
    "Y_pred_rf_dev = rf_clf.predict(X_dev)\n",
    "acc_rf_train = accuracy_score(Y_pred_rf_train, Y_train)\n",
    "acc_rf_dev = accuracy_score(Y_pred_rf_dev, Y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd8f786",
   "metadata": {},
   "source": [
    "# Model 2: Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3ec9e9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=3, n_estimators=1000; total time=   0.9s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=3, n_estimators=1000; total time=   0.9s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=3, n_estimators=1000; total time=   0.9s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=3, n_estimators=1000; total time=   0.9s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=3, n_estimators=1000; total time=   0.9s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=3, n_estimators=2000; total time=   1.8s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=3, n_estimators=2000; total time=   1.8s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=3, n_estimators=2000; total time=   1.9s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=3, n_estimators=2000; total time=   1.8s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=3, n_estimators=2000; total time=   1.7s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=3, n_estimators=5000; total time=   4.4s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=3, n_estimators=5000; total time=   4.5s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=3, n_estimators=5000; total time=   4.4s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=3, n_estimators=5000; total time=   4.5s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=3, n_estimators=5000; total time=   4.4s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=5, n_estimators=1000; total time=   0.9s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=5, n_estimators=1000; total time=   0.9s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=5, n_estimators=1000; total time=   0.9s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=5, n_estimators=1000; total time=   1.0s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=5, n_estimators=1000; total time=   1.0s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=5, n_estimators=2000; total time=   1.9s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=5, n_estimators=2000; total time=   1.8s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=5, n_estimators=2000; total time=   1.8s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=5, n_estimators=2000; total time=   1.8s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=5, n_estimators=2000; total time=   1.7s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=5, n_estimators=5000; total time=   4.5s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=5, n_estimators=5000; total time=   4.4s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=5, n_estimators=5000; total time=   4.5s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=5, n_estimators=5000; total time=   4.4s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=5, n_estimators=5000; total time=   4.6s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=8, n_estimators=1000; total time=   1.0s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=8, n_estimators=1000; total time=   1.0s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=8, n_estimators=1000; total time=   1.0s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=8, n_estimators=1000; total time=   0.9s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=8, n_estimators=1000; total time=   0.9s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=8, n_estimators=2000; total time=   1.7s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=8, n_estimators=2000; total time=   1.8s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=8, n_estimators=2000; total time=   1.8s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=8, n_estimators=2000; total time=   1.8s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=8, n_estimators=2000; total time=   1.9s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=8, n_estimators=5000; total time=   4.4s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=8, n_estimators=5000; total time=   4.4s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=8, n_estimators=5000; total time=   4.5s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=8, n_estimators=5000; total time=   4.4s\n",
      "[CV] END max_depth=3, max_features=auto, min_samples_leaf=8, n_estimators=5000; total time=   4.4s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=3, n_estimators=1000; total time=   0.9s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=3, n_estimators=1000; total time=   0.9s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=3, n_estimators=1000; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=3, n_estimators=1000; total time=   0.9s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=3, n_estimators=1000; total time=   0.9s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=3, n_estimators=2000; total time=   1.8s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=3, n_estimators=2000; total time=   1.9s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=3, n_estimators=2000; total time=   1.9s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=3, n_estimators=2000; total time=   1.9s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=3, n_estimators=2000; total time=   1.9s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=3, n_estimators=5000; total time=   4.6s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=3, n_estimators=5000; total time=   4.7s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=3, n_estimators=5000; total time=   4.6s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=3, n_estimators=5000; total time=   4.6s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=3, n_estimators=5000; total time=   4.6s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=5, n_estimators=1000; total time=   0.9s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=5, n_estimators=1000; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=5, n_estimators=1000; total time=   0.9s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=5, n_estimators=1000; total time=   0.9s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=5, n_estimators=1000; total time=   0.9s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=5, n_estimators=2000; total time=   1.9s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=5, n_estimators=2000; total time=   1.8s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=5, n_estimators=2000; total time=   1.8s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=5, n_estimators=2000; total time=   1.9s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=5, n_estimators=2000; total time=   1.9s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=5, n_estimators=5000; total time=   4.7s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=5, n_estimators=5000; total time=   4.6s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=5, n_estimators=5000; total time=   4.6s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=5, n_estimators=5000; total time=   4.6s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=5, n_estimators=5000; total time=   4.6s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=8, n_estimators=1000; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=8, n_estimators=1000; total time=   0.9s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=8, n_estimators=1000; total time=   0.9s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=8, n_estimators=1000; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=8, n_estimators=1000; total time=   0.9s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=8, n_estimators=2000; total time=   1.8s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=8, n_estimators=2000; total time=   1.9s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=8, n_estimators=2000; total time=   1.8s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=8, n_estimators=2000; total time=   1.9s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=8, n_estimators=2000; total time=   1.8s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=8, n_estimators=5000; total time=   4.8s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=8, n_estimators=5000; total time=   4.6s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=8, n_estimators=5000; total time=   4.5s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=8, n_estimators=5000; total time=   4.6s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_leaf=8, n_estimators=5000; total time=   4.6s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=3, n_estimators=1000; total time=   0.9s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=3, n_estimators=1000; total time=   1.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=3, n_estimators=1000; total time=   1.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=3, n_estimators=1000; total time=   0.9s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=3, n_estimators=1000; total time=   0.9s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=3, n_estimators=2000; total time=   1.9s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=3, n_estimators=2000; total time=   1.9s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=3, n_estimators=2000; total time=   1.9s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=3, n_estimators=2000; total time=   1.9s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=3, n_estimators=2000; total time=   2.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=3, n_estimators=5000; total time=   4.8s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=3, n_estimators=5000; total time=   4.8s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=3, n_estimators=5000; total time=   4.7s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=3, n_estimators=5000; total time=   4.8s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=3, n_estimators=5000; total time=   4.8s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=5, n_estimators=1000; total time=   0.9s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=5, n_estimators=1000; total time=   1.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=5, n_estimators=1000; total time=   1.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=5, n_estimators=1000; total time=   1.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=5, n_estimators=1000; total time=   0.9s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=5, n_estimators=2000; total time=   1.9s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=5, n_estimators=2000; total time=   1.9s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=5, n_estimators=2000; total time=   1.9s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=5, n_estimators=2000; total time=   1.9s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=5, n_estimators=2000; total time=   1.9s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=5, n_estimators=5000; total time=   4.7s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=5, n_estimators=5000; total time=   4.9s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=5, n_estimators=5000; total time=   4.8s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=5, n_estimators=5000; total time=   4.7s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=5, n_estimators=5000; total time=   4.8s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=8, n_estimators=1000; total time=   0.9s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=8, n_estimators=1000; total time=   1.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=8, n_estimators=1000; total time=   1.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=8, n_estimators=1000; total time=   0.9s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=8, n_estimators=1000; total time=   0.9s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=8, n_estimators=2000; total time=   1.9s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=8, n_estimators=2000; total time=   1.9s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=8, n_estimators=2000; total time=   1.9s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=8, n_estimators=2000; total time=   1.8s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=8, n_estimators=2000; total time=   1.9s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=8, n_estimators=5000; total time=   4.7s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=8, n_estimators=5000; total time=   4.7s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=8, n_estimators=5000; total time=   4.7s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=8, n_estimators=5000; total time=   4.7s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_leaf=8, n_estimators=5000; total time=   4.6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=RandomForestClassifier(max_depth=8, min_samples_leaf=3,\n",
       "                                              n_estimators=1000),\n",
       "             param_grid={'max_depth': [3, 5, 8], 'max_features': ['auto'],\n",
       "                         'min_samples_leaf': [3, 5, 8],\n",
       "                         'n_estimators': [1000, 2000, 5000]},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_clf = GradientBoostingClassifier()\n",
    "\n",
    "param = {\n",
    "        'n_estimators': [1000, 2000, 5000],\n",
    "        'min_samples_leaf': [3, 5, 8],\n",
    "        'max_depth': [3, 5, 8],\n",
    "        'max_features': ['auto']\n",
    "        }\n",
    "\n",
    "gb_clf_cv = GridSearchCV(rf_clf, param_grid = param, scoring = 'accuracy', cv=5, verbose=2)\n",
    "gb_clf_cv.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cfdb314c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf = GradientBoostingClassifier(**gb_clf_cv.best_params_)\n",
    "\n",
    "gb_clf.fit(X_train, Y_train)\n",
    "Y_pred_gb_train = gb_clf.predict(X_train)\n",
    "Y_pred_gb_dev = gb_clf.predict(X_dev)\n",
    "acc_gb_train = accuracy_score(Y_pred_gb_train, Y_train)\n",
    "acc_gb_dev = accuracy_score(Y_pred_gb_dev, Y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45d388e",
   "metadata": {},
   "source": [
    "# Model 3: Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2a56ae0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=10, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=10, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=10, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=10, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=10, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=10, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=10, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=10, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=10, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=10, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=100, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=100, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=100, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=100, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=100, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=100, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=100, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=100, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=100, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=100, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=100, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=100, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=100, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=100, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=100, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=10, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=10, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=10, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=10, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=10, kernel=linear; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=10, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=10, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=10, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=10, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=10, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=100, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=100, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=100, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=100, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=100, kernel=linear; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=100, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=100, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=100, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=100, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=100, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=100, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=100, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=100, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=100, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=100, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=10, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=10, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=10, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=10, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=10, kernel=linear; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=10, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=10, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=10, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=10, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=10, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=100, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=100, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=100, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=100, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=100, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=100, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=100, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=100, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=100, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=100, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=100, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=100, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=100, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=100, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=100, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.1, kernel=linear; total time=   0.4s\n",
      "[CV] END ....................C=100, gamma=0.1, kernel=linear; total time=   0.1s\n",
      "[CV] END ....................C=100, gamma=0.1, kernel=linear; total time=   0.1s\n",
      "[CV] END ....................C=100, gamma=0.1, kernel=linear; total time=   0.7s\n",
      "[CV] END ....................C=100, gamma=0.1, kernel=linear; total time=   0.5s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=1, kernel=linear; total time=   0.4s\n",
      "[CV] END ......................C=100, gamma=1, kernel=linear; total time=   0.1s\n",
      "[CV] END ......................C=100, gamma=1, kernel=linear; total time=   0.1s\n",
      "[CV] END ......................C=100, gamma=1, kernel=linear; total time=   0.7s\n",
      "[CV] END ......................C=100, gamma=1, kernel=linear; total time=   0.5s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.1s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.1s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.1s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=10, kernel=linear; total time=   0.4s\n",
      "[CV] END .....................C=100, gamma=10, kernel=linear; total time=   0.1s\n",
      "[CV] END .....................C=100, gamma=10, kernel=linear; total time=   0.1s\n",
      "[CV] END .....................C=100, gamma=10, kernel=linear; total time=   0.7s\n",
      "[CV] END .....................C=100, gamma=10, kernel=linear; total time=   0.5s\n",
      "[CV] END ........................C=100, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=100, gamma=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=10, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=10, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=10, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=10, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=10, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=100, kernel=linear; total time=   0.4s\n",
      "[CV] END ....................C=100, gamma=100, kernel=linear; total time=   0.1s\n",
      "[CV] END ....................C=100, gamma=100, kernel=linear; total time=   0.1s\n",
      "[CV] END ....................C=100, gamma=100, kernel=linear; total time=   0.7s\n",
      "[CV] END ....................C=100, gamma=100, kernel=linear; total time=   0.5s\n",
      "[CV] END .......................C=100, gamma=100, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=100, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=100, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=100, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=100, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=100, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=100, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=100, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=100, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=100, kernel=sigmoid; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100], 'gamma': [0.1, 1, 10, 100],\n",
       "                         'kernel': ['linear', 'rbf', 'sigmoid']},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_clf = SVC()\n",
    "\n",
    "param = {\n",
    "        'kernel': ['linear', 'rbf', 'sigmoid'],\n",
    "        'gamma': [0.1, 1, 10, 100],\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        }\n",
    "\n",
    "svc_clf_cv = GridSearchCV(svc_clf, param_grid = param, scoring = 'accuracy', cv=5, verbose=2)\n",
    "svc_clf_cv.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8466f007",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_clf = SVC(**svc_clf_cv.best_params_)\n",
    "\n",
    "svc_clf.fit(X_train, Y_train)\n",
    "Y_pred_svc_train = svc_clf.predict(X_train)\n",
    "Y_pred_svc_dev = svc_clf.predict(X_dev)\n",
    "acc_svc_train = accuracy_score(Y_pred_svc_train, Y_train)\n",
    "acc_svc_dev = accuracy_score(Y_pred_svc_dev, Y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3629ce",
   "metadata": {},
   "source": [
    "# Model 4: Cat Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "325b31c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV] END depth=3, iterations=500, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.3s\n",
      "[CV] END depth=3, iterations=500, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.2s\n",
      "[CV] END depth=3, iterations=500, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.2s\n",
      "[CV] END depth=3, iterations=500, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.2s\n",
      "[CV] END depth=3, iterations=500, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.3s\n",
      "[CV] END depth=3, iterations=500, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.3s\n",
      "[CV] END depth=3, iterations=500, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.3s\n",
      "[CV] END depth=3, iterations=500, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.3s\n",
      "[CV] END depth=3, iterations=500, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.3s\n",
      "[CV] END depth=3, iterations=500, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.3s\n",
      "[CV] END depth=3, iterations=500, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.3s\n",
      "[CV] END depth=3, iterations=500, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.3s\n",
      "[CV] END depth=3, iterations=500, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.3s\n",
      "[CV] END depth=3, iterations=500, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.3s\n",
      "[CV] END depth=3, iterations=500, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.3s\n",
      "[CV] END depth=3, iterations=1000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.5s\n",
      "[CV] END depth=3, iterations=1000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.5s\n",
      "[CV] END depth=3, iterations=1000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.5s\n",
      "[CV] END depth=3, iterations=1000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.5s\n",
      "[CV] END depth=3, iterations=1000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.4s\n",
      "[CV] END depth=3, iterations=1000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.5s\n",
      "[CV] END depth=3, iterations=1000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.5s\n",
      "[CV] END depth=3, iterations=1000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.4s\n",
      "[CV] END depth=3, iterations=1000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.5s\n",
      "[CV] END depth=3, iterations=1000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.5s\n",
      "[CV] END depth=3, iterations=1000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.5s\n",
      "[CV] END depth=3, iterations=1000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.6s\n",
      "[CV] END depth=3, iterations=1000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.5s\n",
      "[CV] END depth=3, iterations=1000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.5s\n",
      "[CV] END depth=3, iterations=1000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.5s\n",
      "[CV] END depth=3, iterations=2000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.9s\n",
      "[CV] END depth=3, iterations=2000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.9s\n",
      "[CV] END depth=3, iterations=2000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.9s\n",
      "[CV] END depth=3, iterations=2000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.9s\n",
      "[CV] END depth=3, iterations=2000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.9s\n",
      "[CV] END depth=3, iterations=2000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.9s\n",
      "[CV] END depth=3, iterations=2000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.9s\n",
      "[CV] END depth=3, iterations=2000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.9s\n",
      "[CV] END depth=3, iterations=2000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.9s\n",
      "[CV] END depth=3, iterations=2000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.9s\n",
      "[CV] END depth=3, iterations=2000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.9s\n",
      "[CV] END depth=3, iterations=2000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   1.1s\n",
      "[CV] END depth=3, iterations=2000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.9s\n",
      "[CV] END depth=3, iterations=2000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.9s\n",
      "[CV] END depth=3, iterations=2000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.9s\n",
      "[CV] END depth=3, iterations=3000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   1.3s\n",
      "[CV] END depth=3, iterations=3000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   1.4s\n",
      "[CV] END depth=3, iterations=3000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   1.3s\n",
      "[CV] END depth=3, iterations=3000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   1.3s\n",
      "[CV] END depth=3, iterations=3000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   1.3s\n",
      "[CV] END depth=3, iterations=3000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   1.4s\n",
      "[CV] END depth=3, iterations=3000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   1.4s\n",
      "[CV] END depth=3, iterations=3000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   1.3s\n",
      "[CV] END depth=3, iterations=3000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   1.3s\n",
      "[CV] END depth=3, iterations=3000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   1.4s\n",
      "[CV] END depth=3, iterations=3000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   1.4s\n",
      "[CV] END depth=3, iterations=3000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   1.4s\n",
      "[CV] END depth=3, iterations=3000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   1.3s\n",
      "[CV] END depth=3, iterations=3000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   1.3s\n",
      "[CV] END depth=3, iterations=3000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   1.5s\n",
      "[CV] END depth=4, iterations=500, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.3s\n",
      "[CV] END depth=4, iterations=500, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.3s\n",
      "[CV] END depth=4, iterations=500, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.3s\n",
      "[CV] END depth=4, iterations=500, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.3s\n",
      "[CV] END depth=4, iterations=500, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.3s\n",
      "[CV] END depth=4, iterations=500, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.3s\n",
      "[CV] END depth=4, iterations=500, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.3s\n",
      "[CV] END depth=4, iterations=500, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.3s\n",
      "[CV] END depth=4, iterations=500, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.3s\n",
      "[CV] END depth=4, iterations=500, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.3s\n",
      "[CV] END depth=4, iterations=500, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.3s\n",
      "[CV] END depth=4, iterations=500, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.3s\n",
      "[CV] END depth=4, iterations=500, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.3s\n",
      "[CV] END depth=4, iterations=500, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.4s\n",
      "[CV] END depth=4, iterations=500, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.3s\n",
      "[CV] END depth=4, iterations=1000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.5s\n",
      "[CV] END depth=4, iterations=1000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.6s\n",
      "[CV] END depth=4, iterations=1000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.5s\n",
      "[CV] END depth=4, iterations=1000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.6s\n",
      "[CV] END depth=4, iterations=1000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.6s\n",
      "[CV] END depth=4, iterations=1000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.6s\n",
      "[CV] END depth=4, iterations=1000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.5s\n",
      "[CV] END depth=4, iterations=1000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.5s\n",
      "[CV] END depth=4, iterations=1000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.6s\n",
      "[CV] END depth=4, iterations=1000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.6s\n",
      "[CV] END depth=4, iterations=1000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.5s\n",
      "[CV] END depth=4, iterations=1000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.5s\n",
      "[CV] END depth=4, iterations=1000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.6s\n",
      "[CV] END depth=4, iterations=1000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.5s\n",
      "[CV] END depth=4, iterations=1000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.5s\n",
      "[CV] END depth=4, iterations=2000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   1.0s\n",
      "[CV] END depth=4, iterations=2000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   1.1s\n",
      "[CV] END depth=4, iterations=2000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   1.1s\n",
      "[CV] END depth=4, iterations=2000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   1.1s\n",
      "[CV] END depth=4, iterations=2000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   1.1s\n",
      "[CV] END depth=4, iterations=2000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   1.1s\n",
      "[CV] END depth=4, iterations=2000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   1.0s\n",
      "[CV] END depth=4, iterations=2000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   1.0s\n",
      "[CV] END depth=4, iterations=2000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   1.1s\n",
      "[CV] END depth=4, iterations=2000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   1.1s\n",
      "[CV] END depth=4, iterations=2000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   1.1s\n",
      "[CV] END depth=4, iterations=2000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   1.1s\n",
      "[CV] END depth=4, iterations=2000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   1.1s\n",
      "[CV] END depth=4, iterations=2000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   1.1s\n",
      "[CV] END depth=4, iterations=2000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   1.1s\n",
      "[CV] END depth=4, iterations=3000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   1.8s\n",
      "[CV] END depth=4, iterations=3000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   1.5s\n",
      "[CV] END depth=4, iterations=3000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   1.5s\n",
      "[CV] END depth=4, iterations=3000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   1.5s\n",
      "[CV] END depth=4, iterations=3000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   1.6s\n",
      "[CV] END depth=4, iterations=3000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   1.6s\n",
      "[CV] END depth=4, iterations=3000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   1.6s\n",
      "[CV] END depth=4, iterations=3000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   1.5s\n",
      "[CV] END depth=4, iterations=3000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   1.6s\n",
      "[CV] END depth=4, iterations=3000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   1.5s\n",
      "[CV] END depth=4, iterations=3000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   1.6s\n",
      "[CV] END depth=4, iterations=3000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   1.6s\n",
      "[CV] END depth=4, iterations=3000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   1.7s\n",
      "[CV] END depth=4, iterations=3000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   1.6s\n",
      "[CV] END depth=4, iterations=3000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   1.5s\n",
      "[CV] END depth=5, iterations=500, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.3s\n",
      "[CV] END depth=5, iterations=500, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.3s\n",
      "[CV] END depth=5, iterations=500, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.3s\n",
      "[CV] END depth=5, iterations=500, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.3s\n",
      "[CV] END depth=5, iterations=500, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.3s\n",
      "[CV] END depth=5, iterations=500, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.3s\n",
      "[CV] END depth=5, iterations=500, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.4s\n",
      "[CV] END depth=5, iterations=500, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.4s\n",
      "[CV] END depth=5, iterations=500, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.4s\n",
      "[CV] END depth=5, iterations=500, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.3s\n",
      "[CV] END depth=5, iterations=500, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.3s\n",
      "[CV] END depth=5, iterations=500, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.3s\n",
      "[CV] END depth=5, iterations=500, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.4s\n",
      "[CV] END depth=5, iterations=500, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.3s\n",
      "[CV] END depth=5, iterations=500, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.3s\n",
      "[CV] END depth=5, iterations=1000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.7s\n",
      "[CV] END depth=5, iterations=1000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.6s\n",
      "[CV] END depth=5, iterations=1000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.6s\n",
      "[CV] END depth=5, iterations=1000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.7s\n",
      "[CV] END depth=5, iterations=1000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.7s\n",
      "[CV] END depth=5, iterations=1000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.6s\n",
      "[CV] END depth=5, iterations=1000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.7s\n",
      "[CV] END depth=5, iterations=1000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.7s\n",
      "[CV] END depth=5, iterations=1000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.7s\n",
      "[CV] END depth=5, iterations=1000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.7s\n",
      "[CV] END depth=5, iterations=1000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.7s\n",
      "[CV] END depth=5, iterations=1000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.7s\n",
      "[CV] END depth=5, iterations=1000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.8s\n",
      "[CV] END depth=5, iterations=1000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.7s\n",
      "[CV] END depth=5, iterations=1000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.6s\n",
      "[CV] END depth=5, iterations=2000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   1.3s\n",
      "[CV] END depth=5, iterations=2000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   1.3s\n",
      "[CV] END depth=5, iterations=2000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   1.3s\n",
      "[CV] END depth=5, iterations=2000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   1.4s\n",
      "[CV] END depth=5, iterations=2000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   1.3s\n",
      "[CV] END depth=5, iterations=2000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   1.3s\n",
      "[CV] END depth=5, iterations=2000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   1.3s\n",
      "[CV] END depth=5, iterations=2000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   1.3s\n",
      "[CV] END depth=5, iterations=2000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   1.3s\n",
      "[CV] END depth=5, iterations=2000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   1.4s\n",
      "[CV] END depth=5, iterations=2000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   1.3s\n",
      "[CV] END depth=5, iterations=2000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   1.3s\n",
      "[CV] END depth=5, iterations=2000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   1.4s\n",
      "[CV] END depth=5, iterations=2000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   1.4s\n",
      "[CV] END depth=5, iterations=2000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   1.3s\n",
      "[CV] END depth=5, iterations=3000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   1.9s\n",
      "[CV] END depth=5, iterations=3000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   2.0s\n",
      "[CV] END depth=5, iterations=3000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   2.0s\n",
      "[CV] END depth=5, iterations=3000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   1.9s\n",
      "[CV] END depth=5, iterations=3000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   2.0s\n",
      "[CV] END depth=5, iterations=3000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   2.0s\n",
      "[CV] END depth=5, iterations=3000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   2.0s\n",
      "[CV] END depth=5, iterations=3000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   2.1s\n",
      "[CV] END depth=5, iterations=3000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   2.0s\n",
      "[CV] END depth=5, iterations=3000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   2.0s\n",
      "[CV] END depth=5, iterations=3000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   2.0s\n",
      "[CV] END depth=5, iterations=3000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   1.9s\n",
      "[CV] END depth=5, iterations=3000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   2.0s\n",
      "[CV] END depth=5, iterations=3000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   2.1s\n",
      "[CV] END depth=5, iterations=3000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   2.0s\n",
      "[CV] END depth=6, iterations=500, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.4s\n",
      "[CV] END depth=6, iterations=500, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.4s\n",
      "[CV] END depth=6, iterations=500, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.4s\n",
      "[CV] END depth=6, iterations=500, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.4s\n",
      "[CV] END depth=6, iterations=500, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.4s\n",
      "[CV] END depth=6, iterations=500, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.5s\n",
      "[CV] END depth=6, iterations=500, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.5s\n",
      "[CV] END depth=6, iterations=500, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.5s\n",
      "[CV] END depth=6, iterations=500, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.5s\n",
      "[CV] END depth=6, iterations=500, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.4s\n",
      "[CV] END depth=6, iterations=500, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.5s\n",
      "[CV] END depth=6, iterations=500, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.5s\n",
      "[CV] END depth=6, iterations=500, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.5s\n",
      "[CV] END depth=6, iterations=500, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.5s\n",
      "[CV] END depth=6, iterations=500, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.5s\n",
      "[CV] END depth=6, iterations=1000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.9s\n",
      "[CV] END depth=6, iterations=1000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.9s\n",
      "[CV] END depth=6, iterations=1000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   1.0s\n",
      "[CV] END depth=6, iterations=1000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.9s\n",
      "[CV] END depth=6, iterations=1000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   0.9s\n",
      "[CV] END depth=6, iterations=1000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.9s\n",
      "[CV] END depth=6, iterations=1000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.9s\n",
      "[CV] END depth=6, iterations=1000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.9s\n",
      "[CV] END depth=6, iterations=1000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.9s\n",
      "[CV] END depth=6, iterations=1000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   0.9s\n",
      "[CV] END depth=6, iterations=1000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.9s\n",
      "[CV] END depth=6, iterations=1000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.9s\n",
      "[CV] END depth=6, iterations=1000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.9s\n",
      "[CV] END depth=6, iterations=1000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.9s\n",
      "[CV] END depth=6, iterations=1000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   0.9s\n",
      "[CV] END depth=6, iterations=2000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   1.9s\n",
      "[CV] END depth=6, iterations=2000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   1.8s\n",
      "[CV] END depth=6, iterations=2000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   1.7s\n",
      "[CV] END depth=6, iterations=2000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   1.8s\n",
      "[CV] END depth=6, iterations=2000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   1.8s\n",
      "[CV] END depth=6, iterations=2000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   1.7s\n",
      "[CV] END depth=6, iterations=2000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   1.8s\n",
      "[CV] END depth=6, iterations=2000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   1.8s\n",
      "[CV] END depth=6, iterations=2000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   1.7s\n",
      "[CV] END depth=6, iterations=2000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   1.7s\n",
      "[CV] END depth=6, iterations=2000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   1.9s\n",
      "[CV] END depth=6, iterations=2000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   1.9s\n",
      "[CV] END depth=6, iterations=2000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   1.8s\n",
      "[CV] END depth=6, iterations=2000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   1.9s\n",
      "[CV] END depth=6, iterations=2000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   1.9s\n",
      "[CV] END depth=6, iterations=3000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   2.6s\n",
      "[CV] END depth=6, iterations=3000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   2.7s\n",
      "[CV] END depth=6, iterations=3000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   2.8s\n",
      "[CV] END depth=6, iterations=3000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   2.7s\n",
      "[CV] END depth=6, iterations=3000, learning_rate=0.0001, thread_count=-1, verbose=False; total time=   2.7s\n",
      "[CV] END depth=6, iterations=3000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   2.6s\n",
      "[CV] END depth=6, iterations=3000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   2.8s\n",
      "[CV] END depth=6, iterations=3000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   2.6s\n",
      "[CV] END depth=6, iterations=3000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   2.7s\n",
      "[CV] END depth=6, iterations=3000, learning_rate=0.001, thread_count=-1, verbose=False; total time=   2.6s\n",
      "[CV] END depth=6, iterations=3000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   2.9s\n",
      "[CV] END depth=6, iterations=3000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   2.7s\n",
      "[CV] END depth=6, iterations=3000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   3.1s\n",
      "[CV] END depth=6, iterations=3000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   3.0s\n",
      "[CV] END depth=6, iterations=3000, learning_rate=0.01, thread_count=-1, verbose=False; total time=   2.9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=<catboost.core.CatBoostClassifier object at 0x120fe13d0>,\n",
       "             param_grid={'depth': [3, 4, 5, 6],\n",
       "                         'iterations': [500, 1000, 2000, 3000],\n",
       "                         'learning_rate': [0.0001, 0.001, 0.01],\n",
       "                         'thread_count': [-1], 'verbose': [False]},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_clf = CatBoostClassifier()\n",
    "\n",
    "param = {\n",
    "         'verbose': [False],\n",
    "         'thread_count': [-1],\n",
    "         'depth': [3, 4, 5, 6],\n",
    "         'iterations': [500, 1000, 2000, 3000],\n",
    "         'learning_rate': [0.0001, 0.001, 0.01]\n",
    "        }\n",
    "\n",
    "cb_clf_cv = GridSearchCV(cb_clf, param_grid = param, scoring = 'accuracy', cv=5, verbose=2)\n",
    "cb_clf_cv.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e2f1eb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_clf = CatBoostClassifier(**cb_clf_cv.best_params_)\n",
    "\n",
    "cb_clf.fit(X_train, Y_train)\n",
    "Y_pred_cb_train = cb_clf.predict(X_train)\n",
    "Y_pred_cb_dev = cb_clf.predict(X_dev)\n",
    "acc_cb_train = accuracy_score(Y_pred_cb_train, Y_train)\n",
    "acc_cb_dev = accuracy_score(Y_pred_cb_dev, Y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f861ac0e",
   "metadata": {},
   "source": [
    "# Selecting Model With Highest Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a01e5c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train_Set_Accuracy</th>\n",
       "      <th>Dev_Set_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.860335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.991573</td>\n",
       "      <td>0.782123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Kernel</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.849162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cat Boost Classifier</td>\n",
       "      <td>0.880618</td>\n",
       "      <td>0.837989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model  Train_Set_Accuracy  Dev_Set_Accuracy\n",
       "0                 Random Forest            0.859551          0.860335\n",
       "1  Gradient Boosting Classifier            0.991573          0.782123\n",
       "2         Support Vector Kernel            0.835674          0.849162\n",
       "3          Cat Boost Classifier            0.880618          0.837989"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models =['Random Forest', 'Gradient Boosting Classifier', 'Support Vector Kernel', 'Cat Boost Classifier']\n",
    "acc_train = [acc_rf_train, acc_gb_train, acc_svc_train, acc_cb_train]\n",
    "acc_dev = [acc_rf_dev, acc_gb_dev, acc_svc_dev, acc_cb_dev]\n",
    "\n",
    "models_cv_scores = pd.DataFrame({'Model': models, 'Train_Set_Accuracy': acc_train, 'Dev_Set_Accuracy': acc_dev,})\n",
    "models_cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4e380333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model is:  Random Forest , with an Accuracy of 0.8603351955307262\n"
     ]
    }
   ],
   "source": [
    "acc_max = models_cv_scores['Dev_Set_Accuracy'].max()\n",
    "idx = models_cv_scores['Dev_Set_Accuracy'].idxmax()\n",
    "model_max = models_cv_scores.iloc[idx,0]\n",
    "\n",
    "print(\"The best model is: \", model_max, \", with an Accuracy of\", acc_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b77a3431",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "57a1383a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfGender['Survived'] = list(map(int, y_pred))\n",
    "dfGender.to_csv(\"Submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a472acb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
