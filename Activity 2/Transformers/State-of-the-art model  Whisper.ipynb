{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61dddc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "73125d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration, pipeline\n",
    "import datasets\n",
    "from datasets import Audio, load_dataset\n",
    "import soundfile\n",
    "import librosa\n",
    "import torch\n",
    "from evaluate import load\n",
    "from IPython.display import Audio, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d77dd4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and processor\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny\")\n",
    "model.config.forced_decoder_ids = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "85b019c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading metadata...: 16354it [00:01, 12073.23it/s]\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'librosa.core'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-d5221d4e4c61>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"mozilla-foundation/common_voice_11_0\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"en\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"validation\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstreaming\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#ds = ds.cast_column(\"audio\", Audio(rate=16000))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0minput_speech\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0minput_speech\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#input_features = processor(input_speech[\"array\"], sampling_rate=input_speech[\"sampling_rate\"], return_tensors=\"pt\").input_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\iterable_dataset.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\iterable_dataset.py\u001b[0m in \u001b[0;36m_apply_feature_types_on_example\u001b[1;34m(example, features, token_per_repo_id)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\features\\features.py\u001b[0m in \u001b[0;36mdecode_example\u001b[1;34m(self, example, token_per_repo_id)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\features\\features.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\features\\features.py\u001b[0m in \u001b[0;36mdecode_nested_example\u001b[1;34m(schema, obj, token_per_repo_id)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\features\\audio.py\u001b[0m in \u001b[0;36mdecode_example\u001b[1;34m(self, value, token_per_repo_id)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\lazy_loader\\__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'librosa.core'"
     ]
    }
   ],
   "source": [
    "# Load dummy dataset and read audio files\n",
    "ds = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"en\", split=\"validation\", streaming=True)\n",
    "#ds = ds.cast_column(\"audio\", Audio(rate=16000))\n",
    "input_speech = next(iter(ds))\n",
    "input_speech\n",
    "#input_features = processor(input_speech[\"array\"], sampling_rate=input_speech[\"sampling_rate\"], return_tensors=\"pt\").input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e295e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b44102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate token ids\n",
    "predicted_ids = model.generate(input_features)\n",
    "# decode token ids to text\n",
    "transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37da386",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsTest = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"en\", split=\"test\", streaming=True)\n",
    "dsTest = dsTest.cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fbd8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_pred(batch):\n",
    "    audio = batch[\"audio\"]\n",
    "    input_features = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"], return_tensors=\"pt\").input_features\n",
    "    batch[\"reference\"] = processor.tokenizer._normalize(batch['text'])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predicted_ids = model.generate(input_features.to(\"cuda\"))[0]\n",
    "    transcription = processor.decode(predicted_ids)\n",
    "    batch[\"prediction\"] = processor.tokenizer._normalize(transcription)\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ce6bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = dsTest.map(map_to_pred)\n",
    "dsTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50806c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "wer=load(\"wer\")\n",
    "wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f5316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(100 * wer.compute(references=result[\"reference\"], predictions=result[\"prediction\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14ff191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Speech audio file\n",
    "sample_speech1 = display(Audio('Conference.wav', autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a110de",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features1 = processor(sample_speech1).input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8b23af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
